{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Business data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "biz_file = open(\"/Users/ktxdev/Documents/MS in AI/Data Acquisition & Management/Datasets/yelp/yelp_academic_dataset_business.json\")\n",
    "biz_df = pd.DataFrame([json.loads(x) for x in biz_file.readlines()])\n",
    "biz_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the reviews file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_file = open(\"/Users/ktxdev/Documents/MS in AI/Data Acquisition & Management/Datasets/yelp/yelp_academic_dataset_review.json\")\n",
    "reviews_df = pd.DataFrame([json.loads(x) for x in reviews_file.readlines()])\n",
    "reviews_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting out Nightlife and Restaurants only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_biz = biz_df[biz_df['categories'].apply(lambda x: any(x is not None and cat in x for cat in ['Nightlife', 'Restaurants']))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Joining all the reviews for the two types of business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_biz_reviews = two_biz.merge(reviews_df, on='business_id', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_biz_reviews = two_biz_reviews[['business_id', 'name', 'stars_y', 'text', 'categories']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target column with Nightlife as True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_biz_reviews['target'] = two_biz_reviews.apply(lambda x: 'Nightlife' in x['categories'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a balanced classification dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107783, 6)\n",
      "(46193, 6)\n"
     ]
    }
   ],
   "source": [
    "nightlife = two_biz_reviews[two_biz_reviews.apply(lambda x: 'Nightlife' in x['categories'], axis=1)]\n",
    "restaurants = two_biz_reviews[two_biz_reviews.apply(lambda x: 'Rastaurants' in x['categories'], axis=1)]\n",
    "\n",
    "nightlife_subset = nightlife.sample(frac=0.1, random_state=123)\n",
    "restaurants_subset = restaurants.sample(frac=0.021, random_state=123)\n",
    "\n",
    "two_biz_reviews_subset = pd.concat([nightlife_subset, restaurants_subset])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(two_biz_reviews_subset, train_size=0.7, random_state=123)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67289\n",
      "  (0, 64949)\t1\n",
      "  (0, 63617)\t1\n",
      "  (0, 3339)\t1\n",
      "  (0, 64690)\t1\n",
      "  (0, 60569)\t2\n",
      "  (0, 26478)\t1\n",
      "  (0, 28836)\t1\n",
      "  (0, 10094)\t2\n",
      "  (0, 60063)\t1\n",
      "  (0, 64765)\t1\n",
      "  (0, 42800)\t1\n",
      "  (0, 23481)\t2\n",
      "  (0, 60376)\t1\n",
      "  (0, 36697)\t1\n",
      "  (0, 49861)\t1\n",
      "  (0, 21782)\t1\n",
      "  (0, 19965)\t1\n",
      "  (0, 59847)\t7\n",
      "  (0, 65042)\t1\n",
      "  (0, 31929)\t3\n",
      "  (0, 63878)\t1\n",
      "  (0, 10092)\t1\n",
      "  (0, 53230)\t1\n",
      "  (0, 31873)\t2\n",
      "  (0, 21948)\t1\n",
      "  :\t:\n",
      "  (107782, 45190)\t1\n",
      "  (107782, 14870)\t1\n",
      "  (107782, 24850)\t1\n",
      "  (107782, 22839)\t1\n",
      "  (107782, 30719)\t3\n",
      "  (107782, 40472)\t2\n",
      "  (107782, 38161)\t1\n",
      "  (107782, 45609)\t1\n",
      "  (107782, 40855)\t1\n",
      "  (107782, 59184)\t1\n",
      "  (107782, 54170)\t1\n",
      "  (107782, 44647)\t1\n",
      "  (107782, 61650)\t1\n",
      "  (107782, 60099)\t1\n",
      "  (107782, 5122)\t1\n",
      "  (107782, 19402)\t1\n",
      "  (107782, 61043)\t1\n",
      "  (107782, 40118)\t1\n",
      "  (107782, 3138)\t1\n",
      "  (107782, 53281)\t1\n",
      "  (107782, 59574)\t1\n",
      "  (107782, 44286)\t1\n",
      "  (107782, 53648)\t1\n",
      "  (107782, 47034)\t1\n",
      "  (107782, 54953)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "bow_transform = CountVectorizer()\n",
    "X_tr_bow = bow_transform.fit_transform(train_data['text'])\n",
    "X_te_bow = bow_transform.transform(test_data['text'])\n",
    "\n",
    "print(len(bow_transform.vocabulary_))\n",
    "\n",
    "y_tr = train_data['target']\n",
    "y_te = test_data['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the tf-idf representation using the bag-of-words matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer(norm=None)\n",
    "\n",
    "X_tr_tfidf = tfidf_transformer.fit_transform(X_tr_bow)\n",
    "X_te_tfidf = tfidf_transformer.transform(X_te_bow)\n",
    "\n",
    "# l2-normalize the bag-of-words representation\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "X_tr_l2 = normalize(X_tr_bow, axis=0)\n",
    "X_te_l2 = normalize(X_te_bow, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training logistic regression classifiers with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This solver needs samples of at least 2 classes in the data, but the data contains only one class: True",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[67], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest score with\u001b[39m\u001b[38;5;124m\"\u001b[39m, description, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures:\u001b[39m\u001b[38;5;124m'\u001b[39m, s)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m m\n\u001b[0;32m----> 9\u001b[0m m1 \u001b[38;5;241m=\u001b[39m simple_logistic_classify(X_tr_bow, y_tr, X_te_bow, y_te, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbow\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m m2 \u001b[38;5;241m=\u001b[39m simple_logistic_classify(X_tr_l2, y_tr, X_te_l2, y_te, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml2-normalized\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m m3 \u001b[38;5;241m=\u001b[39m simple_logistic_classify(X_tr_tfidf, y_tr, X_te_tfidf, y_te, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtf-idf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[67], line 4\u001b[0m, in \u001b[0;36msimple_logistic_classify\u001b[0;34m(X_tr, y_tr, X_test, y_test, description)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimple_logistic_classify\u001b[39m(X_tr, y_tr, X_test, y_test, description):\n\u001b[0;32m----> 4\u001b[0m     m \u001b[38;5;241m=\u001b[39m LogisticRegression(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m123\u001b[39m)\u001b[38;5;241m.\u001b[39mfit(X_tr, y_tr)\n\u001b[1;32m      5\u001b[0m     s \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mscore(X_test, y_test)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest score with\u001b[39m\u001b[38;5;124m\"\u001b[39m, description, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfeatures:\u001b[39m\u001b[38;5;124m'\u001b[39m, s)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:1241\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1239\u001b[0m classes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_classes \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m-> 1241\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis solver needs samples of at least 2 classes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1243\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in the data, but the data contains only one\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1244\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m class: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1245\u001b[0m         \u001b[38;5;241m%\u001b[39m classes_[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1246\u001b[0m     )\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   1249\u001b[0m     n_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: This solver needs samples of at least 2 classes in the data, but the data contains only one class: True"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def simple_logistic_classify(X_tr, y_tr, X_test, y_test, description):\n",
    "    m = LogisticRegression(random_state=123).fit(X_tr, y_tr)\n",
    "    s = m.score(X_test, y_test)\n",
    "    print(\"Test score with\", description, 'features:', s)\n",
    "    return m\n",
    "\n",
    "m1 = simple_logistic_classify(X_tr_bow, y_tr, X_te_bow, y_te, 'bow')\n",
    "m2 = simple_logistic_classify(X_tr_l2, y_tr, X_te_l2, y_te, 'l2-normalized')\n",
    "m3 = simple_logistic_classify(X_tr_tfidf, y_tr, X_te_tfidf, y_te, 'tf-idf')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
